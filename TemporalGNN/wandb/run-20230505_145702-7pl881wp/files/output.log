Total data points:  223
Total data points:  32
Total data points:  205
  0%|                                                                                                   | 0/223 [00:00<?, ?it/s]
Start Training
> /DATATWO/users/mincut/Object-Centric-VideoAnswering/TemporalGNN/model.py(26)forward()
-> output = []
> /DATATWO/users/mincut/Object-Centric-VideoAnswering/TemporalGNN/model.py(27)forward()
-> for i in range(self.num_timestamps_out):
> /DATATWO/users/mincut/Object-Centric-VideoAnswering/TemporalGNN/model.py(28)forward()
-> h = self.tgnn(x.double(), edge_index)
torch.Size([4, 2, 12])
> /DATATWO/users/mincut/Object-Centric-VideoAnswering/TemporalGNN/model.py(29)forward()
-> h = F.relu(h)
tensor([[ 0.0485, -0.0385, -0.1227,  0.0525, -0.0379, -0.0608, -0.0739,  0.0368,
          0.0037,  0.0861,  0.0751,  0.0600,  0.0859,  0.0809, -0.0495,  0.0408],
        [ 0.0485, -0.0385, -0.1227,  0.0525, -0.0379, -0.0608, -0.0739,  0.0368,
          0.0037,  0.0861,  0.0751,  0.0600,  0.0859,  0.0809, -0.0495,  0.0408],
        [ 0.0485, -0.0385, -0.1227,  0.0525, -0.0379, -0.0608, -0.0739,  0.0368,
          0.0037,  0.0861,  0.0751,  0.0600,  0.0859,  0.0809, -0.0495,  0.0408],
        [ 0.0485, -0.0385, -0.1227,  0.0525, -0.0379, -0.0608, -0.0739,  0.0368,
          0.0037,  0.0861,  0.0751,  0.0600,  0.0859,  0.0809, -0.0495,  0.0408]],
       device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)
torch.Size([4, 16])
> /DATATWO/users/mincut/Object-Centric-VideoAnswering/TemporalGNN/model.py(30)forward()
-> h = self.linear(h)
> /DATATWO/users/mincut/Object-Centric-VideoAnswering/TemporalGNN/model.py(31)forward()
-> h = h.reshape((h.shape[0], 2, 1))
> /DATATWO/users/mincut/Object-Centric-VideoAnswering/TemporalGNN/model.py(32)forward()
-> x = torch.cat((x[:, :, 1:], h), dim=2)
torch.Size([4, 2, 1])
torch.Size([4, 2, 1])
torch.Size([4, 2, 12])
> /DATATWO/users/mincut/Object-Centric-VideoAnswering/TemporalGNN/model.py(33)forward()
-> output.append(h)
torch.Size([4, 2, 12])
> /DATATWO/users/mincut/Object-Centric-VideoAnswering/TemporalGNN/model.py(27)forward()
-> for i in range(self.num_timestamps_out):
> /DATATWO/users/mincut/Object-Centric-VideoAnswering/TemporalGNN/model.py(28)forward()
-> h = self.tgnn(x.double(), edge_index)
> /DATATWO/users/mincut/Object-Centric-VideoAnswering/TemporalGNN/model.py(29)forward()
-> h = F.relu(h)
> /DATATWO/users/mincut/Object-Centric-VideoAnswering/TemporalGNN/model.py(30)forward()
-> h = self.linear(h)
> /DATATWO/users/mincut/Object-Centric-VideoAnswering/TemporalGNN/model.py(31)forward()
-> h = h.reshape((h.shape[0], 2, 1))
> /DATATWO/users/mincut/Object-Centric-VideoAnswering/TemporalGNN/model.py(32)forward()
-> x = torch.cat((x[:, :, 1:], h), dim=2)
*** NameError: name 'nn' is not defined
*** NameError: name 'nn' is not defined
*** NameError: name 'nnn' is not defined
> /DATATWO/users/mincut/Object-Centric-VideoAnswering/TemporalGNN/model.py(33)forward()
-> output.append(h)
> /DATATWO/users/mincut/Object-Centric-VideoAnswering/TemporalGNN/model.py(27)forward()
-> for i in range(self.num_timestamps_out):
> /DATATWO/users/mincut/Object-Centric-VideoAnswering/TemporalGNN/model.py(28)forward()
-> h = self.tgnn(x.double(), edge_index)
> /DATATWO/users/mincut/Object-Centric-VideoAnswering/TemporalGNN/model.py(29)forward()
-> h = F.relu(h)
> /DATATWO/users/mincut/Object-Centric-VideoAnswering/TemporalGNN/model.py(30)forward()
-> h = self.linear(h)
> /DATATWO/users/mincut/Object-Centric-VideoAnswering/TemporalGNN/model.py(31)forward()
-> h = h.reshape((h.shape[0], 2, 1))
> /DATATWO/users/mincut/Object-Centric-VideoAnswering/TemporalGNN/model.py(32)forward()
-> x = torch.cat((x[:, :, 1:], h), dim=2)
> /DATATWO/users/mincut/Object-Centric-VideoAnswering/TemporalGNN/model.py(33)forward()
-> output.append(h)
> /DATATWO/users/mincut/Object-Centric-VideoAnswering/TemporalGNN/model.py(27)forward()
-> for i in range(self.num_timestamps_out):
> /DATATWO/users/mincut/Object-Centric-VideoAnswering/TemporalGNN/model.py(34)forward()
-> output = torch.cat(output, dim=2)
> /DATATWO/users/mincut/Object-Centric-VideoAnswering/TemporalGNN/model.py(35)forward()
-> return output
tensor([[[-0.0190, -0.0191, -0.0203],
         [ 0.0553,  0.0556,  0.0566]],
        [[-0.0190, -0.0191, -0.0203],
         [ 0.0553,  0.0556,  0.0566]],
        [[-0.0190, -0.0191, -0.0203],
         [ 0.0553,  0.0556,  0.0566]],
        [[-0.0190, -0.0191, -0.0203],
         [ 0.0553,  0.0556,  0.0566]]], device='cuda:0', dtype=torch.float64,
       grad_fn=<CatBackward0>)
  0%|                                                                                                   | 0/223 [12:28<?, ?it/s]
Traceback (most recent call last):
  File "/DATATWO/users/mincut/Object-Centric-VideoAnswering/TemporalGNN/main.py", line 182, in <module>
    train(epoch,plot=plot)
  File "/DATATWO/users/mincut/Object-Centric-VideoAnswering/TemporalGNN/main.py", line 102, in train
    out = model(data.x, data.edge_index)
  File "/home/mincut/miniconda3/envs/vidgnn/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/DATATWO/users/mincut/Object-Centric-VideoAnswering/TemporalGNN/model.py", line 35, in forward
    return output
  File "/DATATWO/users/mincut/Object-Centric-VideoAnswering/TemporalGNN/model.py", line 35, in forward
    return output
  File "/home/mincut/miniconda3/envs/vidgnn/lib/python3.10/bdb.py", line 90, in trace_dispatch
    return self.dispatch_line(frame)
  File "/home/mincut/miniconda3/envs/vidgnn/lib/python3.10/bdb.py", line 115, in dispatch_line
    if self.quitting: raise BdbQuit
bdb.BdbQuit